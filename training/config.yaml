# LSTM 訓練配置

model:
  type: lstm
  input_size: 44  # 技術指標數量
  hidden_size: 128
  num_layers: 2
  output_size: 1
  dropout: 0.3
  bidirectional: true

training:
  epochs: 200
  batch_size: 32
  learning_rate: 0.001
  weight_decay: 0.0001
  lookback_window: 60
  forecast_horizon: 1
  train_split: 0.8
  val_split: 0.1
  test_split: 0.1

optimization:
  optimizer: adam
  scheduler: cosine  # warmup + cosine annealing
  warmup_steps: 500
  patience: 20
  min_delta: 1e-6

data:
  timeframe: 1h
  limit: 5000  # 最近三个月
  normalize: true
  augmentation: false

logging:
  verbose: true
  log_every: 10
  save_best_only: true
  save_interval: 5

device: cuda  # cuda 或 cpu
